# GUÍA DE ESCRITURA DE BLOG - SAMPLIT

## FORMATO ADICTIVO vs ACADÉMICO

### ❌ Formato académico aburrido:
```
# Título genérico

Introducción larga explicando contexto...

Sección 1 con teoría...

Sección 2 con más teoría...

Conclusión obvia...
```

**Nadie lo lee.**

---

### ✅ Formato adictivo (lo que funciona):
```
# Título específico y curioso

[HOOK INMEDIATO - Primera frase]

[PROBLEMA RELATABLE]

[PROMESA DE LO QUE APRENDERÁN]

---

[CONTENIDO EN SECCIONES CORTAS]

[DATA/SCREENSHOTS]

[INSIGHT SORPRENDENTE]

[APLICACIÓN PRÁCTICA]

---

[CONCLUSIÓN ACCIONABLE]

[CTA SUAVE]
```

---

## FÓRMULAS PARA TÍTULOS (80% del éxito)

### ❌ MALO:
"Cómo hacer A/B testing efectivo"

### ✅ BUENO:
"Perdimos €15,000 en 3 semanas haciendo A/B testing 'correcto'"

### ✅ BUENO:
"Testeamos 47 headlines. Solo 3 funcionaron. Aquí está por qué."

### ✅ BUENO:
"El botón rojo no ganó (y otras mentiras sobre optimización)"

### Fórmula:
- [Número específico] + [Resultado sorprendente/contraintuitivo]
- [Creencia común] + [Por qué está mal]
- [Experiencia personal] + [Lección aprendida]

---

## HOOK (Primeras 2-3 frases - CRÍTICO)

**Objetivo:** Que sigan leyendo.

### ❌ MALO:
```
El A/B testing es una técnica importante para 
optimizar conversiones. En este artículo vamos 
a explorar diferentes metodologías...
```

**Nadie sigue leyendo.**

### ✅ BUENO:
```
Gasté €15,000 en ads el mes pasado.

€7,500 fueron a una landing page que PERDÍA 
contra la otra variante.

Durante 3 semanas. Porque estaba esperando 
"significancia estadística".

Esto es lo que hice mal:
```

### ✅ BUENO:
```
47 headlines testeadas.
21 no cambiaron nada.
23 empeoraron conversión.
3 la mejoraron significativamente.

¿Puedes adivinar qué tenían en común las 3 ganadoras?

(No es lo que piensas)
```

### ✅ BUENO:
```
"El botón rojo convierte mejor."

He escuchado esto 1,000 veces.

Lo testeamos en 12 páginas diferentes.

El rojo ganó en 3.
Perdió en 9.

Aquí está lo que realmente importa:
```

### Fórmula del hook:
1. Statement sorprendente (dato, pérdida, contradicción)
2. Amplificación (más contexto que genera curiosidad)
3. Promesa de resolver la intriga ("Aquí está por qué...")

---

## ESTRUCTURA DEL CONTENIDO

```markdown
# [Título específico y curioso]

[HOOK - 2-3 frases]

---

## El problema (relatable)

[Describe el problema de forma que el lector piense 
"sí, exacto, me pasa"]

---

## Lo que probamos

[Data específica, no teoría]

**Setup:**
- [Detalle 1]
- [Detalle 2]

**Variantes:**
[Screenshots o descripción visual]

---

## Resultados (con data real)

[Gráfico del dashboard]

- Variante A: [resultado]
- Variante B: [resultado]
- Variante C: [resultado]

**Ganador:** [X]

---

## El plot twist

[Algo sorprendente/contraintuitivo de los resultados]

No esperábamos que [X], pero [Y].

---

## Por qué funcionó (o no funcionó)

[Tu hipótesis + explicación]

**Factores que influyeron:**
1. [Factor 1]
2. [Factor 2]

---

## Qué puedes aplicar tú

[Takeaways accionables, numerados]

1. **[Acción específica]**
   Por qué: [razón]
   Cómo: [pasos]

2. **[Acción específica]**
   [Mismo formato]

---

## Conclusión

[1-2 párrafos máximo]

[Reafirma el aprendizaje principal]

[CTA suave]

---

**¿Quieres ver los datos completos de este test?**
[Link al dashboard público de este experimento específico]

**¿Probando Samplit?**
[Link suave, no agresivo]
```

---

## EJEMPLOS CONCRETOS

### Post 1: Test fallido (credibilidad)

```markdown
# Gastamos €2,400 en un test que fracasó. Aquí está por qué.

El mes pasado decidí rediseñar completamente 
nuestra pricing page.

Contraté un diseñador. Quedó preciosa. 
Colores on-brand, spacing perfecto, tipografía 
elegante.

La lancé confiado.

**Resultado:** -18% en conversión.

Sí, MENOS conversión.

Esto es lo que aprendí:

---

## El contexto

Nuestra pricing page era fea. Admitámoslo.

Tabla simple en Tailwind, nada de gradientes, 
sin iconos fancy.

Pero funcionaba. 3.2% de visitantes elegían plan.

"Seguro que con mejor diseño mejora", pensé.

---

## El rediseño

[Screenshot: versión antigua vs nueva]

**Versión nueva:**
- Gradientes modernos
- Iconos custom
- Animaciones suaves
- Comparativa visual elegante

**Versión antigua:**
- Tabla básica
- Texto plano
- Botones simples
- Cero animaciones

---

## Los resultados (duelen)

[Gráfico del dashboard mostrando la caída]

**Después de 2,847 visitantes:**
- Versión antigua: 3.2% conversión
- Versión nueva: 2.6% conversión (-18%)

**Confianza estadística:** 96%

No era ruido. La nueva versión PERDÍA.

---

## Por qué fracasó (mi hipótesis)

**Teoría 1: Cognitive load**
Más elementos = más decisiones = parálisis

**Teoría 2: Timing de animaciones**
Las animaciones retrasaban la aparición de 
información crítica

**Teoría 3: Trust**
Irónicamente, el diseño "muy pulido" puede 
parecer menos auténtico

**Lo que creo que pasó:**
El diseño distraía del mensaje principal.

Los usuarios venían a comparar precios, no a 
admirar gradientes.

---

## Qué haría diferente

1. **Tests incrementales, no redesigns completos**
   Cambiar una cosa a la vez.

2. **Forma sigue función**
   Diseño bonito es secundario a claridad.

3. **No asumir nada**
   "Seguro que esto mejora" = receta para perder dinero.

4. **Test rápido con poco tráfico primero**
   No gastes €2,400 antes de validar.

---

## Conclusión

Diseño bonito ≠ mejor conversión.

A veces lo simple y directo gana.

Testea siempre. No asumas.

He vuelto a la versión "fea". Mis conversiones 
están contentas.

---

**Moraleja:** Gastamos €2,400 para aprender que 
no debía gastar €2,400.

¿Tú qué tests has hecho que fracasaron? Me 
encantaría saber.

---

**¿Probando Samplit?**  
Es la herramienta que usé para medir este fracaso 
épico. [Link]
```

---

### Post 2: Data interesante (curiosidad)

```markdown
# Analizamos 2,847 experimentos. Esto es lo que descubrimos.

Tenemos acceso a datos de todos los experimentos 
que corren en Samplit.

(Agregados y anónimos, obviamente)

Los patrones son fascinantes.

Aquí están los 5 hallazgos más sorprendentes:

---

## Hallazgo 1: Los tests simples ganan más

**Data:**
- Tests de 2 variantes: 34% encuentran ganador
- Tests de 3-4 variantes: 28% encuentran ganador
- Tests de 5+ variantes: 19% encuentran ganador

**Por qué:**
Con muchas variantes, necesitas MÁS tráfico 
para llegar a significancia.

**Takeaway:**
2-3 variantes es el sweet spot.

---

## Hallazgo 2: Los martes convierten mejor

[Gráfico de conversión por día de semana]

**Data:**
- Lunes: 2.1% conversión promedio
- Martes: 2.8% conversión promedio ← Peak
- Miércoles: 2.6%
- Jueves: 2.4%
- Viernes: 2.0%
- Fin de semana: 1.7%

**Por qué (hipótesis):**
- Lunes: la gente está organizándose
- Martes: ya están en modo trabajo pero no agobiados
- Viernes: ya desconectaron

**Takeaway:**
Lanza tests importantes un lunes para capturar 
el tráfico del martes.

---

## Hallazgo 3: E-commerce testea precios, SaaS testea copy

[Gráfico de qué testea cada industria]

**E-commerce:**
- 43% testea precios/descuentos
- 28% testea imágenes de producto
- 29% testea copy

**SaaS:**
- 61% testea headlines/copy
- 25% testea CTAs
- 14% testea pricing

**Por qué:**
Cada industria tiene su palanca principal.

**Takeaway:**
Empieza por lo que tu industria ya sabe que importa.

---

## Hallazgo 4: Mobile convierte peor, pero...

**Data general:**
- Desktop: 3.2% conversión promedio
- Mobile: 1.8% conversión promedio

**PERO en e-commerce:**
- Desktop: 2.8%
- Mobile: 2.9% ← Mobile gana

**Por qué:**
E-commerce está optimizado para mobile.
SaaS todavía no.

**Takeaway:**
Si eres SaaS, tu mobile experience necesita trabajo.

---

## Hallazgo 5: El color rojo NO gana siempre

**Tests donde un botón rojo compite:**
- Rojo gana: 38%
- Rojo pierde: 43%
- No hay diferencia: 19%

**Por qué:**
El color importa menos que el CONTEXTO.

**Takeaway:**
Para de buscar "el color perfecto" y testea 
en TU contexto específico.

---

## Conclusión

Data > opinión.

Estas son tendencias generales. Tu caso 
puede ser diferente.

Por eso testeas.

---

**¿Quieres ver más data como esta?**
Me suscribo a tu newsletter si te interesa que 
publique este tipo de análisis mensualmente.

[Simple form de email]
```

---

### Post 3: Contraintuitivo (engagement)

```markdown
# 5 "best practices" de optimización que son mentira

Todos repiten estos consejos.

Yo también lo hacía.

Hasta que los testeé.

Spoiler: La mayoría no funcionan.

---

## Mentira 1: "El botón rojo convierte mejor"

**Lo que dice internet:**
Rojo = urgencia = más clicks

**Lo que muestran nuestros datos:**
Rojo gana en 38% de tests.
Pierde en 43%.

**Por qué es mentira:**
El color importa menos que el contraste 
y el contexto.

**Qué funciona:**
Testea el color que contrasta más con tu 
diseño actual, sea cual sea.

---

## Mentira 2: "Las landings largas convierten mejor"

**Lo que dice internet:**
Más información = más confianza = más conversión

**Lo que muestran nuestros datos:**
No hay correlación entre longitud y conversión.

Hemos visto:
- Landings de 500 palabras con 8% CR
- Landings de 5,000 palabras con 2% CR
- Y viceversa

**Por qué es mentira:**
Depende de tu producto y momento del buyer journey.

**Qué funciona:**
Match la longitud con la complejidad/precio 
de tu producto.

---

## Mentira 3: "Tests de 2 semanas son suficientes"

**Lo que dice internet:**
Corre tests 2 semanas, luego decide.

**Lo que muestran nuestros datos:**
El 64% de tests NO alcanzan significancia 
en 2 semanas.

[Gráfico de tiempo hasta significancia]

**Por qué es mentira:**
2 semanas es arbitrario. Depende de tu tráfico.

**Qué funciona:**
Corre tests hasta alcanzar significancia O 
hasta que el coste de oportunidad sea 
demasiado alto.

---

## Mentira 4: "Urgencia siempre funciona"

**Lo que dice internet:**
"Solo quedan 3" "Oferta termina hoy"

**Lo que muestran nuestros datos:**
Urgencia funciona... 52% de las veces.
48% la ignoran o desconfían.

**Por qué es mentira:**
La audiencia tech/informada detecta urgencia 
falsa y desconfía.

**Qué funciona:**
Urgencia REAL (stock limitado real, oferta 
real) funciona. Urgencia inventada puede 
hacerte daño.

---

## Mentira 5: "Testea todo al mismo tiempo"

**Lo que dice internet:**
Tests multivariantes son más eficientes.

**Lo que muestran nuestros datos:**
- Tests simples (2-3 variantes): encuentran ganador en promedio 9 días
- Tests complejos (5+ variantes, múltiples elementos): 31 días promedio

**Por qué es mentira:**
Más variantes = necesitas exponencialmente 
más tráfico.

**Qué funciona:**
Tests simples, secuenciales, iterativos.

---

## Conclusión

Best practices ≠ verdad universal.

Son puntos de partida, no dogmas.

Testea en TU contexto.
Tu audiencia es única.

---

**Otras "best practices" que quieres que testee?**
Responde en Twitter: @samplit

[Link suave a Samplit]
```

---

## FORMATO ESTÁNDAR DE POSTS DE TEST

```markdown
# [Título del test]

## Contexto
Estábamos enviando [email X] y notamos [problema/pregunta].

## Hipótesis
Creíamos que [hipótesis].

## Test
Creamos [N] variantes:

**Variante A:**
[Screenshot o descripción]

**Variante B:**
[Screenshot o descripción]

## Setup técnico
- Métrica principal: [X]
- Métrica secundaria: [Y]
- Duración: [Z días]
- Sample size: [N usuarios]

## Resultados
[Gráfico del dashboard de Samplit]

- Variante A: [resultado]
- Variante B: [resultado]
- Ganadora: [X] con [Y]% de confianza

## Aprendizaje
[Qué descubriste]

## Aplicación
Si tú envías [tipo de email], considera [recomendación].

Pero recuerda: tu audiencia puede ser diferente. 
Testea siempre.

---

**¿Quieres ver los datos completos?**
[Link a dashboard público con este test específico]
```

---

## ESTRATEGIA DE CONTENIDO INTEGRADA

### Flujo de contenido:
```
1. Haces un test en Samplit (tu propio uso)
   ↓
2. Obtienes resultados (gane o pierda)
   ↓
3. Escribes blog post (formato adictivo)
   ↓
4. Publicas en blog
   ↓
5. Thread de Twitter resumiendo + link
   ↓
6. Post de LinkedIn (más formal) + link
   ↓
7. Añades a newsletter del mes
   ↓
8. Archivas en /resources
```

**Resultado:** Un test = 4-5 piezas de contenido.

---

## TIPS FINALES

### ✅ Hacer:
- Empezar con hook fuerte
- Usar datos reales
- Ser honesto (incluso con fracasos)
- Conclusiones accionables
- CTA suave, no agresivo

### ❌ Evitar:
- Teoría sin ejemplos
- Introducciones largas
- Conclusiones obvias
- Vender demasiado agresivo
- Prometir resultados imposibles
